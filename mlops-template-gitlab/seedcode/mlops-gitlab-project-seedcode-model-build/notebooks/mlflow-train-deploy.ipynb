{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ML Flow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/rl-market-simulator\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow==1.27.0 in /usr/local/lib/python3.8/site-packages (from -r src/requirements.txt (line 1)) (1.27.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/site-packages (from -r src/requirements.txt (line 2)) (0.11.2)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/site-packages (from -r src/requirements.txt (line 3)) (0.13.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from -r src/requirements.txt (line 4)) (1.2.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from -r src/requirements.txt (line 5)) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (3.1.27)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (0.17.3)\n",
      "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.28.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (8.1.3)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (2021.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.0 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.4.41)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (4.8.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: Flask in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: gunicorn in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (20.1.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (3.19.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.8/site-packages (from mlflow==1.27.0->-r src/requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/site-packages (from seaborn->-r src/requirements.txt (line 2)) (2.2.4)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/site-packages (from statsmodels->-r src/requirements.txt (line 3)) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/site-packages (from pandas->-r src/requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow==1.27.0->-r src/requirements.txt (line 1)) (0.8.9)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow==1.27.0->-r src/requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.8/site-packages (from docker>=4.0.0->mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.26.12)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.8/site-packages (from docker>=4.0.0->mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/site-packages (from gitpython>=2.1.0->mlflow==1.27.0->-r src/requirements.txt (line 1)) (4.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow==1.27.0->-r src/requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn->-r src/requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn->-r src/requirements.txt (line 2)) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn->-r src/requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests>=2.17.3->mlflow==1.27.0->-r src/requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests>=2.17.3->mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests>=2.17.3->mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/site-packages (from sqlalchemy>=1.4.0->mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/site-packages (from alembic->mlflow==1.27.0->-r src/requirements.txt (line 1)) (5.4.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.8/site-packages (from alembic->mlflow==1.27.0->-r src/requirements.txt (line 1)) (1.2.3)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.8/site-packages (from Flask->mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/site-packages (from Flask->mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/site-packages (from Flask->mlflow==1.27.0->-r src/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.8/site-packages (from gunicorn->mlflow==1.27.0->-r src/requirements.txt (line 1)) (59.5.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/site-packages (from prometheus-flask-exporter->mlflow==1.27.0->-r src/requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow==1.27.0->-r src/requirements.txt (line 1)) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/site-packages (from Jinja2>=3.0->Flask->mlflow==1.27.0->-r src/requirements.txt (line 1)) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r src/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Community libraries\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "# AWS libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "\n",
    "# From custom code\n",
    "from src.utils import global_parameters as gp\n",
    "\n",
    "# RLEstimator dependencies\n",
    "#sys.path.append(\"common\")\n",
    "\n",
    "# Logging definition\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Function to download bucket contents for a specific directory\n",
    "def download_s3_folder(bucket_name, s3_folder, local_dir=None):\n",
    "    \"\"\"\n",
    "    Download the contents of a folder directory\n",
    "    Args:\n",
    "        bucket_name: the name of the s3 bucket\n",
    "        s3_folder: the folder path in the s3 bucket\n",
    "        local_dir: a relative or absolute directory path in the local file system\n",
    "    \"\"\"\n",
    "    s3 = boto3.resource('s3') # assumes credentials & configuration are handled outside python in .aws directory or environment variables\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    for obj in bucket.objects.filter(Prefix=s3_folder):\n",
    "        target = obj.key if local_dir is None \\\n",
    "            else os.path.join(local_dir, os.path.relpath(obj.key, s3_folder))\n",
    "        if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(os.path.dirname(target))\n",
    "        if obj.key[-1] == '/':\n",
    "            continue\n",
    "        print(target)\n",
    "        bucket.download_file(obj.key, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup S3 bucket\n",
    "\n",
    "Set up the linkage and authentication to the S3 bucket that you want to use for checkpoint and the metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket path: s3://sagemaker-eu-central-1-961105418118/\n"
     ]
    }
   ],
   "source": [
    "sage_session = sagemaker.session.Session()\n",
    "s3_bucket = sage_session.default_bucket()\n",
    "s3_output_path = \"s3://{}/\".format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tracking RL agent experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#DNS name of the Load Balancer that interacts with fargate cluster in which the MLflow server is installed \n",
    "tracking_uri = 'http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com'\n",
    "rl_experiment_name = 'tfm-market-simulator-v3-sagemaker'\n",
    "\n",
    "# create a descriptive job name\n",
    "job_name_prefix = \"rl-market-simulator\"\n",
    "\n",
    "# RL estimator hyperparamenters\n",
    "hyperparameters = {\n",
    "    'tracking_uri': tracking_uri,\n",
    "    'experiment_name': rl_experiment_name,\n",
    "    'training_iteration': gp.MAX_ITERATIONS,\n",
    "    'gamma': 0.50,\n",
    "    'horizon': gp.AGENT_MAX_STEPS,\n",
    "    'lr': 0.001\n",
    "}\n",
    "\n",
    "# Ray image\n",
    "ray_tf_image = \"462105765813.dkr.ecr.eu-central-1.amazonaws.com/sagemaker-rl-ray-container:ray-1.6.0-tf-cpu-py37\"\n",
    "\n",
    "# RL estimator metrics\n",
    "metric_definitions = [{'Name': 'episode_reward_mean',\n",
    "                      'Regex': 'episode_reward_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "                     {'Name': 'episode_reward_max',\n",
    "                      'Regex': 'episode_reward_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "                     {'Name': 'episode_reward_min',\n",
    "                      'Regex': 'episode_reward_min: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "                     {'Name': 'training_iteration',\n",
    "                      'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "                     {'Name': 'entropy',\n",
    "                      'Regex': 'entropy: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}]\n",
    "\n",
    "# ML FLow Tags definition\n",
    "mlflow_tags = {\"businessunit\": \"machinelearninglab\",\n",
    "        \"subunit\": \"machinelearninglab\",\n",
    "        \"application\": \"mll-tfm-market-simulator\",\n",
    "        \"account\": \"mll-dev\",\n",
    "        \"env\": \"dev\",\n",
    "        \"service\": \"mll-tfm-market-simulator-model-repository\",\n",
    "        \"version\": \"3.0.0\",\n",
    "        \"contact\": \"General - Machine Learning Lab <a44e37f5.TUIGroup.onmicrosoft.com@emea.teams.ms>\",\n",
    "        \"classification\": \"internal\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training without tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logging input hyperparameters\n",
      "INFO:root:Train the reinforcement learning agent.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py37\n",
      "INFO:sagemaker:Creating training-job with name: rl-market-simulator-2022-10-03-14-30-21-288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-03 14:30:22 Starting - Starting the training job...\n",
      "2022-10-03 14:30:38 Starting - Preparing the instances for trainingProfilerReport-1664807421: InProgress\n",
      "......\n",
      "2022-10-03 14:31:44 Downloading - Downloading input data......\n",
      "2022-10-03 14:32:44 Training - Downloading the training image...\n",
      "2022-10-03 14:33:16 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:21.135504: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:21.142657: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:21.303324: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:25,389 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:25,398 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:25,779 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting mlflow==1.27.0\n",
      "  Downloading mlflow-1.27.0-py3-none-any.whl (17.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting matplotlib==2.2.4\n",
      "  Downloading matplotlib-2.2.4-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting statsmodels\n",
      "  Downloading statsmodels-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.2.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.19.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker>=4.0.0\n",
      "  Downloading docker-6.0.0-py3-none-any.whl (147 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (20.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (1.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (2.24.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gunicorn in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (20.1.0)\u001b[0m\n",
      "\u001b[34mCollecting alembic\n",
      "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Flask in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (1.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (3.17.3)\u001b[0m\n",
      "\u001b[34mCollecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy>=1.4.0\n",
      "  Downloading SQLAlchemy-1.4.41-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/site-packages (from mlflow==1.27.0->-r requirements.txt (line 1)) (8.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib==2.2.4->-r requirements.txt (line 2)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/site-packages (from matplotlib==2.2.4->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib==2.2.4->-r requirements.txt (line 2)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib==2.2.4->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib==2.2.4->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34mCollecting packaging\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyjwt>=1.7.0\n",
      "  Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow==1.27.0->-r requirements.txt (line 1)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow==1.27.0->-r requirements.txt (line 1)) (0.8.9)\u001b[0m\n",
      "\u001b[34mCollecting requests>=2.17.3\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34mCollecting urllib3>=1.26.0\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\u001b[0m\n",
      "\u001b[34mCollecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow==1.27.0->-r requirements.txt (line 1)) (3.7.4.3)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow==1.27.0->-r requirements.txt (line 1)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.17.3->mlflow==1.27.0->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mCollecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.17.3->mlflow==1.27.0->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/site-packages (from sqlalchemy>=1.4.0->mlflow==1.27.0->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mCollecting Mako\n",
      "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.9.0-py3-none-any.whl (33 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/site-packages (from Flask->mlflow==1.27.0->-r requirements.txt (line 1)) (3.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/site-packages (from Flask->mlflow==1.27.0->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/site-packages (from Flask->mlflow==1.27.0->-r requirements.txt (line 1)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask->mlflow==1.27.0->-r requirements.txt (line 1)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/site-packages (from gunicorn->mlflow==1.27.0->-r requirements.txt (line 1)) (57.0.0)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-client\n",
      "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139102 sha256=bb76bafa8d21e37168d490e5694419a00dcd7adbc5a7e502f105eadec15f25f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/73/87/c1e4b2145eb6049bb6c9aaf7ea1e38302b77ca219b6fef5d5c\u001b[0m\n",
      "\u001b[34mSuccessfully built databricks-cli\u001b[0m\n",
      "\u001b[34mInstalling collected packages: urllib3, smmap, charset-normalizer, websocket-client, sqlalchemy, requests, pyjwt, prometheus-client, packaging, Mako, importlib-resources, gitdb, sqlparse, querystring-parser, prometheus-flask-exporter, patsy, gitpython, entrypoints, docker, databricks-cli, alembic, statsmodels, mlflow, matplotlib\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.24.0\n",
      "    Uninstalling requests-2.24.0:\n",
      "      Successfully uninstalled requests-2.24.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.4.2\n",
      "    Uninstalling matplotlib-3.4.2:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled matplotlib-3.4.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed Mako-1.2.3 alembic-1.8.1 charset-normalizer-2.1.1 databricks-cli-0.17.3 docker-6.0.0 entrypoints-0.4 gitdb-4.0.9 gitpython-3.1.27 importlib-resources-5.9.0 matplotlib-2.2.4 mlflow-1.27.0 packaging-21.3 patsy-0.5.2 prometheus-client-0.14.1 prometheus-flask-exporter-0.20.3 pyjwt-2.5.0 querystring-parser-1.2.4 requests-2.28.1 smmap-5.0.0 sqlalchemy-1.4.41 sqlparse-0.4.3 statsmodels-0.13.2 urllib3-1.26.12 websocket-client-1.4.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:50,330 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:50,363 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:50,396 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-03 14:33:50,417 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator\": \"RLEstimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"experiment_name\": \"tfm-market-simulator-v3-sagemaker\",\n",
      "        \"gamma\": 0.5,\n",
      "        \"horizon\": 100,\n",
      "        \"lr\": 0.001,\n",
      "        \"tracking_uri\": \"http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com\",\n",
      "        \"training_iteration\": 3\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rl-market-simulator-2022-10-03-14-30-21-288\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-961105418118/rl-market-simulator-2022-10-03-14-30-21-288/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"./models/train-rl-market-simulator\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"./models/train-rl-market-simulator.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"experiment_name\":\"tfm-market-simulator-v3-sagemaker\",\"gamma\":0.5,\"horizon\":100,\"lr\":0.001,\"tracking_uri\":\"http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com\",\"training_iteration\":3}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=./models/train-rl-market-simulator.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=./models/train-rl-market-simulator\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-961105418118/rl-market-simulator-2022-10-03-14-30-21-288/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"experiment_name\":\"tfm-market-simulator-v3-sagemaker\",\"gamma\":0.5,\"horizon\":100,\"lr\":0.001,\"tracking_uri\":\"http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com\",\"training_iteration\":3},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rl-market-simulator-2022-10-03-14-30-21-288\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-961105418118/rl-market-simulator-2022-10-03-14-30-21-288/source/sourcedir.tar.gz\",\"module_name\":\"./models/train-rl-market-simulator\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"./models/train-rl-market-simulator.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--experiment_name\",\"tfm-market-simulator-v3-sagemaker\",\"--gamma\",\"0.5\",\"--horizon\",\"100\",\"--lr\",\"0.001\",\"--tracking_uri\",\"http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com\",\"--training_iteration\",\"3\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_EXPERIMENT_NAME=tfm-market-simulator-v3-sagemaker\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=0.5\u001b[0m\n",
      "\u001b[34mSM_HP_HORIZON=100\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_TRACKING_URI=http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_ITERATION=3\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 ./models/train-rl-market-simulator.py --experiment_name tfm-market-simulator-v3-sagemaker --gamma 0.5 --horizon 100 --lr 0.001 --tracking_uri http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com --training_iteration 3\u001b[0m\n",
      "\u001b[34mNo checkpoint path specified. Training from scratch.\u001b[0m\n",
      "\u001b[34mImportant! Ray with version <=0.7.2 may report \"Did not find checkpoint file\" even if the experiment is actually restored successfully. If restoration is expected, please check \"training_iteration\" in the experiment info to confirm.\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 1.6/7.6 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 3.0/3 CPUs, 0/0 GPUs, 0.0/2.74 GiB heap, 0.0/1.37 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+-----------------------+----------+-------+\u001b[0m\n",
      "\u001b[34m| Trial name            | status   | loc   |\u001b[0m\n",
      "\u001b[34m|-----------------------+----------+-------|\u001b[0m\n",
      "\u001b[34m| PPO_myEnv_6afa7_00000 | RUNNING  |       |\u001b[0m\n",
      "\u001b[34m+-----------------------+----------+-------+\u001b[0m\n",
      "\u001b[34mResult for PPO_myEnv_6afa7_00000:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-03_14-35-11\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1113.0\n",
      "  episode_reward_mean: 857.75\n",
      "  episode_reward_min: 625.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 40\n",
      "  experiment_id: d451cfe5ac1c4499b40bd0d7dc063228\n",
      "  hostname: ip-10-0-251-65.eu-central-1.compute.internal\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 0.5\n",
      "          entropy: 0.07044465839862823\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 246.6703643798828\n",
      "          model: {}\n",
      "          policy_loss: 0.6551962494850159\n",
      "          total_loss: 434.5011291503906\n",
      "          vf_explained_var: -0.007929197512567043\n",
      "          vf_loss: 384.51190185546875\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 4000\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.251.65\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.51369863013699\n",
      "    ram_util_percent: 30.31643835616439\n",
      "  pid: 149\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16060696429815488\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 17.942218051321326\n",
      "    mean_inference_ms: 3.618815015519279\n",
      "    mean_raw_obs_processing_ms: 0.40707780026841445\n",
      "  time_since_restore: 53.35972023010254\n",
      "  time_this_iter_s: 53.35972023010254\n",
      "  time_total_s: 53.35972023010254\n",
      "  timers:\n",
      "    learn_throughput: 469.965\n",
      "    learn_time_ms: 8511.268\n",
      "    load_throughput: 54295197.411\n",
      "    load_time_ms: 0.074\n",
      "    sample_throughput: 89.258\n",
      "    sample_time_ms: 44813.733\n",
      "    update_time_ms: 5.256\n",
      "  timestamp: 1664807711\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 6afa7_00000\n",
      "  \u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mMemory usage on this node: 2.3/7.6 GiB\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mResources requested: 3.0/3 CPUs, 0/0 GPUs, 0.0/2.74 GiB heap, 0.0/1.37 GiB objects\u001b[0m\n",
      "\u001b[34mResult logdir: /opt/ml/output/intermediate/training\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+-----------------------+----------+-----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\u001b[0m\n",
      "\u001b[34m| Trial name            | status   | loc             |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\u001b[0m\n",
      "\u001b[34m|-----------------------+----------+-----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\u001b[0m\n",
      "\u001b[34m| PPO_myEnv_6afa7_00000 | RUNNING  | 10.0.251.65:149 |      1 |          53.3597 | 4000 |   857.75 |                 1113 |                  625 |                100 |\u001b[0m\n",
      "\u001b[34m+-----------------------+----------+-----------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Definition of the estimator\n",
    "estimator = RLEstimator(base_job_name=job_name_prefix,\n",
    "                        entry_point='./models/train-rl-market-simulator.py',\n",
    "                        source_dir= 'src',\n",
    "                        #image_name=ray_tf_image,\n",
    "                        dependencies=[\"src/common/sagemaker_rl\"],\n",
    "                        toolkit=RLToolkit.RAY,\n",
    "                        framework=RLFramework.TENSORFLOW,\n",
    "                        toolkit_version=\"1.6.0\",\n",
    "                        role=role,\n",
    "                        debugger_hook_config=False,\n",
    "                        instance_type='ml.m5.large',\n",
    "                        instance_count=1,\n",
    "                        output_path=s3_output_path,\n",
    "                        use_spot_instances=True, # use spot instance\n",
    "                        max_run = 3600, # seconds\n",
    "                        max_wait = 3600, # seconds\n",
    "                        hyperparameters = hyperparameters,\n",
    "                        metric_definitions=metric_definitions,\n",
    "                        )\n",
    "\n",
    "# set remote mlflow server\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(rl_experiment_name)\n",
    "\n",
    "# start mlflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Set the run tags\n",
    "    mlflow.set_tags(mlflow_tags)\n",
    "    \n",
    "    # ML Flow algorith hyperparameters logging \n",
    "    logging.info('Logging input hyperparameters')\n",
    "    mlflow.log_params(hyperparameters)\n",
    "\n",
    "    # fit the RL model\n",
    "    logging.info('Train the reinforcement learning agent.')\n",
    "    estimator.fit(wait=True)\n",
    "    \n",
    "    # get the job name\n",
    "    job_name = estimator.latest_training_job.job_name\n",
    "    print(\"Training job: %s\" % job_name)\n",
    "    \n",
    "    # log the job name associated to this run\n",
    "    logging.info('Logging input hyperparameters')\n",
    "    mlflow.log_params({\"training_job_name\": job_name})\n",
    "\n",
    "    # Log metrics\n",
    "    progress_df = pd.DataFrame()\n",
    "    for metric in ['episode_reward_mean','episode_reward_max','episode_reward_min']:\n",
    "        df = TrainingJobAnalytics(job_name, [metric]).dataframe()\n",
    "        df = df.rename(columns={\"value\":metric})\n",
    "        progress_df = pd.concat([progress_df, df[metric]], axis=1)\n",
    "        for value in df[metric]:\n",
    "            mlflow.log_metric(metric, value)\n",
    "    \n",
    "    # Log progress csv\n",
    "    progress_df.to_csv(f'progress.csv')\n",
    "    mlflow.log_artifact(\"progress.csv\")\n",
    "    \n",
    "    # Log model artifacts\n",
    "    logging.info(f'Get training artifacts from {estimator.model_data}')\n",
    "    download_s3_folder(s3_bucket,job_name,'models')\n",
    "    mlflow.log_artifact(\"models\")\n",
    "    \n",
    "    # end mlflow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, HyperparameterTuner\n",
    "    \n",
    "hyperparameters = {\n",
    "    'tracking_uri': tracking_uri,\n",
    "    'experiment_name': rl_experiment_name,\n",
    "}\n",
    "\n",
    "rl_hyperparameter_ranges = {\n",
    "    'gamma': ContinuousParameter(0.01, 0.99),\n",
    "    'lr': ContinuousParameter(0.0001, 0.001)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check source https://sagemaker-examples.readthedocs.io/en/latest/reinforcement_learning/rl_roboschool_ray/rl_roboschool_ray_automatic_model_tuning.html\n",
    "# for further clarification\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name='episode_reward_mean',\n",
    "                            objective_type='Maximize',\n",
    "                            hyperparameter_ranges=rl_hyperparameter_ranges,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            max_jobs=5,\n",
    "                            max_parallel_jobs=5,\n",
    "                            base_tuning_job_name='tfm-market-simulator-tuning')\n",
    "\n",
    "# set remote mlflow server\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(rl_experiment_name)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Set the run tags\n",
    "    mlflow.set_tags(mlflow_tags)\n",
    "    \n",
    "    # ML Flow algorith hyperparameters logging \n",
    "    #logging.info('Logging tuning hyperparameters')\n",
    "    #mlflow.log_params(rl_hyperparameter_ranges)\n",
    "    \n",
    "    # fit the RL model with tuning\n",
    "    logging.info('Train the reinforcement learning agent.')\n",
    "    tuner.fit(wait=True)\n",
    "    \n",
    "    # ML Flow algorith hyperparameters logging \n",
    "    logging.info('Logging completed run parameters')\n",
    "    mlflow.log_params(tuner.describe()['BestTrainingJob'])\n",
    "    \n",
    "    # get the BEST training run\n",
    "    job_name = tuner.best_training_job()\n",
    "    print(\"Training job: %s\" % job_name)\n",
    "    \n",
    "    # Log metrics\n",
    "    progress_df = pd.DataFrame()\n",
    "    for metric in ['episode_reward_mean','episode_reward_max','episode_reward_min']:\n",
    "        df = TrainingJobAnalytics(job_name, [metric]).dataframe()\n",
    "        df = df.rename(columns={\"value\":metric})\n",
    "        progress_df = pd.concat([progress_df, df[metric]], axis=1)\n",
    "        for value in df[metric]:\n",
    "            mlflow.log_metric(metric, value)\n",
    "            \n",
    "    # Log progress csv\n",
    "    progress_df.to_csv(f'progress.csv')\n",
    "    mlflow.log_artifact(\"progress.csv\")\n",
    "            \n",
    "    # Log model artifacts\n",
    "    logging.info(f'Get training artifacts from training job={job_name}')\n",
    "    download_s3_folder(s3_bucket,job_name,'models')\n",
    "    mlflow.log_artifact(\"models\")\n",
    "    \n",
    "    # end mlflow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model deployment\n",
    "\n",
    "Now let us deploy the RL policy so that we can get the optimal action, given an environment observation.\n",
    "\n",
    "**Note**: Model deployment is supported for TensorFLow only at current stage. \n",
    "\n",
    "STOP HERE IF PYTORCH IS USED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-09-30 09:52:34 Starting - Preparing the instances for training\n",
      "2022-09-30 09:52:34 Downloading - Downloading input data\n",
      "2022-09-30 09:52:34 Training - Training image download completed. Training in progress.\n",
      "2022-09-30 09:52:34 Uploading - Uploading generated training model\n",
      "2022-09-30 09:52:34 Completed - Training job completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-central-1-961105418118/tfm-market-simulator-220930-0944-001-0c6f4dac/output/model.tar.gz'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner.best_estimator().model_data\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tar.gz example\n",
    "model_to_deploy_example = \"s3://sagemaker-eu-central-1-961105418118/1rznlhvopllp-tfm-v3--d5nkL8QAcd-003-122dbef7/output/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/intermediate/training/.tmp_checkpoint\n",
      "tmp/intermediate/training/.tmp_generator\n",
      "tmp/intermediate/training/PPO_myEnv_24abc_00000_0_2022-09-30_09-49-14/checkpoint_000003/.is_checkpoint\n",
      "tmp/intermediate/training/PPO_myEnv_24abc_00000_0_2022-09-30_09-49-14/checkpoint_000003/checkpoint-3\n",
      "tmp/intermediate/training/PPO_myEnv_24abc_00000_0_2022-09-30_09-49-14/checkpoint_000003/checkpoint-3.tune_metadata\n",
      "tmp/intermediate/training/PPO_myEnv_24abc_00000_0_2022-09-30_09-49-14/events.out.tfevents.1664531355.algo-1\n",
      "tmp/intermediate/training/PPO_myEnv_24abc_00000_0_2022-09-30_09-49-14/params.json\n",
      "tmp/intermediate/training/PPO_myEnv_24abc_00000_0_2022-09-30_09-49-14/params.pkl\n",
      "tmp/intermediate/training/PPO_myEnv_24abc_00000_0_2022-09-30_09-49-14/progress.csv\n",
      "tmp/intermediate/training/PPO_myEnv_24abc_00000_0_2022-09-30_09-49-14/result.json\n",
      "tmp/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# download model\n",
    "download_s3_folder(s3_bucket, 'tfm-market-simulator-220930-0944-001-0c6f4dac/output', local_dir='tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model tar.gz\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(s3_bucket)\n",
    "target = 'tmp'\n",
    "# check if target exists\n",
    "if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(target)\n",
    "bucket.download_file(\"tfm-market-simulator-220930-0944-001-0c6f4dac/output/model.tar.gz\", \"tmp/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker:Creating model with name: tensorflow-inference-2022-10-14-16-18-06-304\n",
      "INFO:sagemaker:Creating endpoint with name tensorflow-inference-2022-10-14-16-18-06-942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "model = TensorFlowModel(model_data=model_to_deploy_example, framework_version=\"2.5.1\", role=role)\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ray 1.6.0 requires all the following inputs, ray 0.8.5 or below remove 'timestep'\n",
    "# 'prev_action', 'is_training', 'prev_reward', 'seq_lens' and 'timestep' are placeholders for this example\n",
    "# they won't affect prediction results\n",
    "\n",
    "# Number of different values stored in at any time in the current state for the TFM market simulator.\n",
    "TFM_BOOKING_CURVE_NUMBER_FEATURES = 21\n",
    "\n",
    "# Sample predictions with random outputs\n",
    "number_of_examples = 10\n",
    "testing_data = np.random.rand(number_of_examples, TFM_BOOKING_CURVE_NUMBER_FEATURES).tolist()\n",
    "\n",
    "input = {\n",
    "    \"inputs\": {\n",
    "        \"observations\": testing_data,\n",
    "        \"prev_action\": [1],\n",
    "        \"is_training\": False,\n",
    "        \"prev_reward\": -1,\n",
    "        \"seq_lens\": -1,\n",
    "        \"timestep\": 1,\n",
    "    }\n",
    "}\n",
    "\n",
    "result = predictor.predict(input)\n",
    "\n",
    "result[\"outputs\"][\"actions_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.576083629471641,\n",
       "  0.1900841856662263,\n",
       "  0.028175621159361564,\n",
       "  0.35442517173266674,\n",
       "  0.9054375392123268,\n",
       "  0.8158723542405849,\n",
       "  0.15997761845254854,\n",
       "  0.6055418081810722,\n",
       "  0.17907020240222793,\n",
       "  0.7489194207620015,\n",
       "  0.8850696660372761,\n",
       "  0.23267985741174269,\n",
       "  0.9441477586953245,\n",
       "  0.9597605804961318,\n",
       "  0.7941387314539569,\n",
       "  0.9369093157914256,\n",
       "  0.8481229877121451,\n",
       "  0.0545036211139488,\n",
       "  0.7318125273327869,\n",
       "  0.8735593658281017,\n",
       "  0.49502695985182277]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1, 21).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: tensorflow-inference-2022-10-14-16-18-06-942\n",
      "INFO:sagemaker:Deleting endpoint with name: tensorflow-inference-2022-10-14-16-18-06-942\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy endpoint as mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.quality_tests import QAforTFM\n",
    "tfm_qa = QAforTFM(rl_training_job = 'fejh754xz0ob-tfm-v3--ISGzUj7dZ3-010-3d789f30', \n",
    "                  rl_artifacts_bucket = s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract rl model tar.gz\n",
    "model_tar_path = 'tmp'\n",
    "tfm_qa.extract_rl_model(model_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,\n",
       "        5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5,\n",
       "       11. , 11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5, 15. , 15.5, 16. ,\n",
       "       16.5, 17. , 17.5, 18. , 18.5, 19. , 19.5, 20. , 20.5, 21. , 21.5,\n",
       "       22. , 22.5, 23. , 23.5, 24. , 24.5, 25. , 25.5, 26. , 26.5, 27. ,\n",
       "       27.5, 28. , 28.5, 29. , 29.5, 30. , 30.5, 31. , 31.5, 32. , 32.5,\n",
       "       33. , 33.5, 34. , 34.5, 35. , 35.5, 36. , 36.5, 37. , 37.5, 38. ,\n",
       "       38.5, 39. , 39.5, 40. , 40.5, 41. , 41.5, 42. , 42.5, 43. , 43.5,\n",
       "       44. , 44.5, 45. , 45.5, 46. , 46.5, 47. , 47.5, 48. , 48.5, 49. ,\n",
       "       49.5, 50. , 50.5, 51. , 51.5, 52. , 52.5, 53. , 53.5, 54. , 54.5,\n",
       "       55. , 55.5, 56. , 56.5, 57. , 57.5, 58. , 58.5, 59. , 59.5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate markups\n",
    "prediction_data = pd.read_csv('s3://mll-mlflow-development-961105418118/15/3616a7af66be4a1782290e2e6606fc4b/artifacts/processed_x_test_data.csv')\n",
    "tfm_qa.markups_unique_values(model_tar_path, prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model tar.gz\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(s3_bucket)\n",
    "target = 'tmp'\n",
    "selected_training_rl_job = 'efkphzjch6z1-tfm-v3--UQkqq2HymU-005-97ff9096' # select the rl training run\n",
    "\n",
    "# check if target exists\n",
    "if not os.path.exists(os.path.dirname(target)):\n",
    "            os.makedirs(target)\n",
    "bucket.download_file(f\"{selected_training_rl_job}/output/model.tar.gz\", f\"{target}/model_new.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the \"tarfile\" module\n",
    "import tarfile\n",
    "  \n",
    "# open file\n",
    "file = tarfile.open(f\"{target}/model_new.tar.gz\")\n",
    "  \n",
    "# extracting file\n",
    "file.extractall(f\"{target}/model\")\n",
    "  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filepath = f\"{target}/model\"\n",
    "rl_model = tf.saved_model.load(f'{filepath}/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "print(list(rl_model.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_prob': <tf.Tensor 'default_policy/Exp:0' shape=(None,) dtype=float32>, 'vf_preds': <tf.Tensor 'default_policy/Reshape:0' shape=(None,) dtype=float32>, 'actions_0': <tf.Tensor 'default_policy/cond_1/Merge:0' shape=(None,) dtype=int64>, 'action_dist_inputs': <tf.Tensor 'default_policy/model/fc_out/BiasAdd:0' shape=(None, 120) dtype=float32>, 'action_logp': <tf.Tensor 'default_policy/cond_2/Merge:0' shape=(None,) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "infer = rl_model.signatures['serving_default']\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import signature_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serve']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag=[tf.saved_model.SERVING]\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'serving_default'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dc9ee20bbd2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# set remote mlflow server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tracking_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tfm-tensorflow-test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'serve'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlflow' is not defined"
     ]
    }
   ],
   "source": [
    "# set remote mlflow server\n",
    "mlflow.set_tracking_uri(\"http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com/\")\n",
    "mlflow.set_experiment(\"tfm-tensorflow-test\")\n",
    "\n",
    "tag = ['serve']\n",
    "key = ['serving_default']\n",
    "\n",
    "# test tensorflow logging\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.tensorflow.log_model(#tf_saved_model_dir=f'{filepath}/1',\n",
    "                         tf_saved_model_dir=f'tmp',\n",
    "                         tf_signature_def_key = key,\n",
    "                         tf_meta_graph_tags = tag,\n",
    "                         artifact_path=\"model\",\n",
    "                         registered_model_name=\"test-tfm\")\n",
    "\n",
    "    \n",
    "    # end mlflow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction pruned(is_training, observations, prev_action, prev_reward, timestep) at 0x7F6697BA30A0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tensorflow model\n",
    "logged_model = 'runs:/6d5da4e4fd5141ed87b70a2f0e5b1dde/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.tensorflow.load_model(logged_model)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example with one prediction\n",
    "TFM_BOOKING_CURVE_NUMBER_FEATURES = 21\n",
    "prediction = loaded_model(is_training = tf.convert_to_tensor(False), \n",
    "                     observations = tf.convert_to_tensor(np.ones(shape=(1, TFM_BOOKING_CURVE_NUMBER_FEATURES)).tolist()), \n",
    "                     prev_action = tf.constant(0, dtype=tf.int64), \n",
    "                     prev_reward = tf.constant(100, dtype=tf.float32), \n",
    "                     timestep=tf.cast(1.0, tf.int64))\n",
    "markup = np.multiply(prediction['actions_0'].numpy(), 0.5)\n",
    "markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read for the predictions\n",
    "data = pd.read_csv('s3://mll-mlflow-development-961105418118/15/3616a7af66be4a1782290e2e6606fc4b/artifacts/processed_x_test_data.csv')\n",
    "data.head()\n",
    "TFM_BOOKING_CURVE_NUMBER_FEATURES = len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 14., 14., ..., 14., 14., 14.])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "prediction = loaded_model(is_training = tf.convert_to_tensor(False), \n",
    "                     observations = tf.convert_to_tensor(data.to_numpy().tolist()), \n",
    "                     prev_action = tf.constant(0, dtype=tf.int64), \n",
    "                     prev_reward = tf.constant(100, dtype=tf.float32), \n",
    "                     timestep=tf.cast(1.0, tf.int64))\n",
    "markup = np.multiply(prediction['actions_0'].numpy(), 0.5)\n",
    "markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 16.])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(markup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9412"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = 16\n",
    "len([value for value in markup if value == reference])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get best run from ML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import os\n",
    "import boto3\n",
    "import warnings\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pathlib\n",
    "from pandas.io.json import json_normalize\n",
    "from scipy import stats\n",
    "\n",
    "import logging\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking.artifact_utils import _download_artifact_from_uri\n",
    "from mlflow.tracking._tracking_service.client import TrackingServiceClient\n",
    "from mlflow.store.entities.paged_list import PagedList\n",
    "from mlflow.entities import Experiment, Run, RunInfo, Param, Metric, RunTag, FileInfo, ViewType\n",
    "\n",
    "# Function to get mlflow runs\n",
    "def update_run_df(run: PagedList[Run])->pd.DataFrame():\n",
    "    df=pd.DataFrame.from_records(list(run)).T\n",
    "    df.columns=df.iloc[0]\n",
    "    df=df[1:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-10-20'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "today_date = datetime.strftime(datetime.now() - timedelta(1), '%Y-%m-%d')\n",
    "#today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "today_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d045a85aa3db487daab84334d438526e'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_uri = 'http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com//'\n",
    "experiment_name = 'tfm-v3-rlestimator+mlflow+pipelines'\n",
    "mlflow_client = TrackingServiceClient(tracking_uri)\n",
    "experiment_id=dict(mlflow_client.get_experiment_by_name(experiment_name))['experiment_id']\n",
    "\n",
    "# get best model for todays runs based on the reward mean\n",
    "runs = mlflow_client.search_runs(experiment_id, \n",
    "                                 filter_string=f\"parameters.training_job_date = '{today_date}'\", \n",
    "                                 order_by=[\"metrics.episode_reward_mean DESC\"], max_results=1)\n",
    "best_run = runs[0]\n",
    "\n",
    "# get mlflow run id\n",
    "best_run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1666262274013"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = mlflow_client.search_runs(experiment_id, \"\", order_by=[\"metrics.episode_reward_mean DESC\"], max_results=1)\n",
    "best_run = runs[0]\n",
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: d414237f97ed4ae5aca24b363c034792\n",
      "Artifacts downloaded in: /opt/ml/processing/evaluation\n",
      "P-value=0.17288628613038395\n",
      "Training reward mean has converged\n"
     ]
    }
   ],
   "source": [
    "# required parameters\n",
    "tracking_uri = 'http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com//'\n",
    "experiment_name = 'tfm-v3-rlestimator+mlflow+pipelines'\n",
    "\n",
    "# Get mlflow data\n",
    "mlflow_client = TrackingServiceClient(tracking_uri)\n",
    "experiment_id=dict(mlflow_client.get_experiment_by_name(experiment_name))['experiment_id']\n",
    "\n",
    "# Get mlflow results\n",
    "runs=pd.DataFrame()\n",
    "for run in mlflow_client.list_run_infos(experiment_id,run_view_type=ViewType.ACTIVE_ONLY):\n",
    "    runs=pd.concat([runs,update_run_df(run)],axis=0)\n",
    "\n",
    "# Remove unfinished runs\n",
    "runs = runs[runs['status']=='FINISHED']\n",
    "\n",
    "# get the most recent run that finished successfully\n",
    "run_id = runs['run_id'][runs['end_time']==max(runs['end_time'])].values[0]\n",
    "print('Run ID:', run_id)\n",
    "\n",
    "# Build model uri\n",
    "model_uri = f'runs:/{run_id}/model'\n",
    "\n",
    "# Build evaluation folder\n",
    "output_dir = \"/opt/ml/processing/evaluation\"\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the artifact to local storage.\n",
    "local_path = mlflow_client.download_artifacts(run_id, \"progress.csv\", output_dir)\n",
    "print(\"Artifacts downloaded in: {}\".format(output_dir))\n",
    "\n",
    "# Read progress data\n",
    "df_progress = pd.read_csv(local_path)\n",
    "\n",
    "# get sample split indexes\n",
    "first_split, second_split = int(df_progress.shape[0]*0.50), int(df_progress.shape[0]*0.75)\n",
    "results = stats.ttest_ind(df_progress['episode_reward_mean'][first_split:second_split], df_progress['episode_reward_mean'][second_split:])\n",
    "print(f\"P-value={results.pvalue}\")\n",
    "\n",
    "if results.pvalue < 0.05:\n",
    "    print(f\"Reject null hypothesis since {results.pvalue}<0.05\")\n",
    "else:\n",
    "    print(f\"Training reward mean has converged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>end_time</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>lifecycle_stage</th>\n",
       "      <th>run_id</th>\n",
       "      <th>run_uuid</th>\n",
       "      <th>start_time</th>\n",
       "      <th>status</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/d4...</td>\n",
       "      <td>1666219460738</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>d414237f97ed4ae5aca24b363c034792</td>\n",
       "      <td>d414237f97ed4ae5aca24b363c034792</td>\n",
       "      <td>1666217023176</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/f3...</td>\n",
       "      <td>1666219233783</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>f3f3b565ac784167a6d3b49c413b4ce7</td>\n",
       "      <td>f3f3b565ac784167a6d3b49c413b4ce7</td>\n",
       "      <td>1666217022167</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/67...</td>\n",
       "      <td>1666219356130</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>67975a7920a941e2a653ebd49d273f2f</td>\n",
       "      <td>67975a7920a941e2a653ebd49d273f2f</td>\n",
       "      <td>1666217015649</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/14...</td>\n",
       "      <td>1666219373563</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>149e8ccc16914abb98b37679474b2192</td>\n",
       "      <td>149e8ccc16914abb98b37679474b2192</td>\n",
       "      <td>1666217015071</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/d2...</td>\n",
       "      <td>1666219451087</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>d22bf2bbdcf841f2848e3e012dea2684</td>\n",
       "      <td>d22bf2bbdcf841f2848e3e012dea2684</td>\n",
       "      <td>1666217012407</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/60...</td>\n",
       "      <td>1664894323625</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>609f531744534003bf7bacb9247a7091</td>\n",
       "      <td>609f531744534003bf7bacb9247a7091</td>\n",
       "      <td>1664894123329</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/c6...</td>\n",
       "      <td>1664894315520</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>c642181f78764417b9cdb959044854ee</td>\n",
       "      <td>c642181f78764417b9cdb959044854ee</td>\n",
       "      <td>1664894118424</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/cd...</td>\n",
       "      <td>1664894296628</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>cd53de0440784875a9c536ce2fed32a1</td>\n",
       "      <td>cd53de0440784875a9c536ce2fed32a1</td>\n",
       "      <td>1664894113896</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/2a...</td>\n",
       "      <td>1664894263682</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>2a6493845ad44402b38e960f3ad79136</td>\n",
       "      <td>2a6493845ad44402b38e960f3ad79136</td>\n",
       "      <td>1664894112718</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://mll-mlflow-development-961105418118/13/a7...</td>\n",
       "      <td>1664883662408</td>\n",
       "      <td>13</td>\n",
       "      <td>active</td>\n",
       "      <td>a76a27f3c1fd4f82a3e0c036a2969b84</td>\n",
       "      <td>a76a27f3c1fd4f82a3e0c036a2969b84</td>\n",
       "      <td>1664883475178</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                        artifact_uri       end_time  \\\n",
       "1   s3://mll-mlflow-development-961105418118/13/d4...  1666219460738   \n",
       "1   s3://mll-mlflow-development-961105418118/13/f3...  1666219233783   \n",
       "1   s3://mll-mlflow-development-961105418118/13/67...  1666219356130   \n",
       "1   s3://mll-mlflow-development-961105418118/13/14...  1666219373563   \n",
       "1   s3://mll-mlflow-development-961105418118/13/d2...  1666219451087   \n",
       "..                                                ...            ...   \n",
       "1   s3://mll-mlflow-development-961105418118/13/60...  1664894323625   \n",
       "1   s3://mll-mlflow-development-961105418118/13/c6...  1664894315520   \n",
       "1   s3://mll-mlflow-development-961105418118/13/cd...  1664894296628   \n",
       "1   s3://mll-mlflow-development-961105418118/13/2a...  1664894263682   \n",
       "1   s3://mll-mlflow-development-961105418118/13/a7...  1664883662408   \n",
       "\n",
       "0  experiment_id lifecycle_stage                            run_id  \\\n",
       "1             13          active  d414237f97ed4ae5aca24b363c034792   \n",
       "1             13          active  f3f3b565ac784167a6d3b49c413b4ce7   \n",
       "1             13          active  67975a7920a941e2a653ebd49d273f2f   \n",
       "1             13          active  149e8ccc16914abb98b37679474b2192   \n",
       "1             13          active  d22bf2bbdcf841f2848e3e012dea2684   \n",
       "..           ...             ...                               ...   \n",
       "1             13          active  609f531744534003bf7bacb9247a7091   \n",
       "1             13          active  c642181f78764417b9cdb959044854ee   \n",
       "1             13          active  cd53de0440784875a9c536ce2fed32a1   \n",
       "1             13          active  2a6493845ad44402b38e960f3ad79136   \n",
       "1             13          active  a76a27f3c1fd4f82a3e0c036a2969b84   \n",
       "\n",
       "0                           run_uuid     start_time    status user_id  \n",
       "1   d414237f97ed4ae5aca24b363c034792  1666217023176  FINISHED    root  \n",
       "1   f3f3b565ac784167a6d3b49c413b4ce7  1666217022167  FINISHED    root  \n",
       "1   67975a7920a941e2a653ebd49d273f2f  1666217015649  FINISHED    root  \n",
       "1   149e8ccc16914abb98b37679474b2192  1666217015071  FINISHED    root  \n",
       "1   d22bf2bbdcf841f2848e3e012dea2684  1666217012407  FINISHED    root  \n",
       "..                               ...            ...       ...     ...  \n",
       "1   609f531744534003bf7bacb9247a7091  1664894123329  FINISHED    root  \n",
       "1   c642181f78764417b9cdb959044854ee  1664894118424  FINISHED    root  \n",
       "1   cd53de0440784875a9c536ce2fed32a1  1664894113896  FINISHED    root  \n",
       "1   2a6493845ad44402b38e960f3ad79136  1664894112718  FINISHED    root  \n",
       "1   a76a27f3c1fd4f82a3e0c036a2969b84  1664883475178  FINISHED    root  \n",
       "\n",
       "[401 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs[runs['status']=='FINISHED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = omlflow._tracking_client.get_run(run_id).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313119830869503"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metrics['training_recall_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'042acd62196741ca9fda2ff28943fffb'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ENDPOINT deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'name': 'tfm-v3-model-test',\n",
       "  'version': 11,\n",
       "  'tracking_uri': 'http://mll-mlflow-development-1-72adb7f6eb3c1c02.elb.eu-central-1.amazonaws.com/',\n",
       "  'location_ssm_parameter': '/tfm/model/location',\n",
       "  'location_ssm_parameter_tf': '/tfm3/model/location'},\n",
       " 'endpoint': {'instance_type': 'ml.m5.xlarge',\n",
       "  'instance_count': 1,\n",
       "  'image_uri': '961105418118.dkr.ecr.eu-central-1.amazonaws.com/mlflow-pyfunc:1.27.0',\n",
       "  'image_uri_tf': '763104351884.dkr.ecr.eu-central-1.amazonaws.com/tensorflow-inference:2.5.1-cpu-py37-ubuntu18.04'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "from src.model_deploy.utils import MLflowHandler\n",
    "\n",
    "\n",
    "# CONFIG\n",
    "with open(\"cfg/model_deploy.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE MLFLOW HANDLER\n",
    "mlflow_handler = MLflowHandler(cfg=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.tar.gz dowloaded from /tmp/tmpx1shtpc7/model/model.tar.gz\n",
      "model.tar.gz uploaded to s3://sagemaker-eu-central-1-961105418118/mlflow_model/tfm-v3-model-test-11/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "mlflow_handler.prepare_sagemaker_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_handler.transition_model_version_stage(\"Staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_handler.transition_model_version_stage(\"Production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Tensorflow container with custom input and output handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/rl-market-simulator\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "# Test tensorflow model deployment\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "model = TensorFlowModel(model_data='s3://mll-mlflow-development-961105418118/13/cd258ca110b6459e8e9fd7c985237c5f/artifacts/model/model.tar.gz', \n",
    "                        entry_point='src/model_deploy/inference.py', \n",
    "                        image_uri='763104351884.dkr.ecr.eu-central-1.amazonaws.com/tensorflow-inference:2.5.1-cpu-py37-ubuntu18.04',\n",
    "                        role=sagemaker.get_execution_role())\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.c5.xlarge', \n",
    "                         endpoint_name='tfm-v3-custom-endpoint-test-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalMarkup': {'adult': 59.0, 'child': 59.0, 'infant': 0.0},\n",
       " 'vatPercentage': '23',\n",
       " 'currency': 'euro',\n",
       " 'markupDetails': [{'adult': 59.0,\n",
       "   'child': 59.0,\n",
       "   'infant': 0.0,\n",
       "   'ruleId': 'TFM-MarginBrain-RL'}],\n",
       " 'markupMethod': 'TFM-MarginBrain-RL',\n",
       " 'supplierPrice': {'adult': 100.0, 'child': 100.0, 'infant': 0.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "input = {\n",
    "  'currency': 'euro',\n",
    "  'vatPercentage': '23',\n",
    "  'supplierPriceAdult': 100\n",
    "}\n",
    "predictor.predict(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build SKlearn container with custom input and output handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/rl-market-simulator\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sklearn model deployment\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.model import Model\n",
    "\n",
    "# get sagemaker session\n",
    "session = sagemaker.Session(boto3.Session(region_name='eu-central-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSOR MODEL\n",
    "preprocessing_model = SKLearnModel(\n",
    "    model_data='s3://sagemaker-eu-central-1-961105418118/Process-TFM-V3-data-90d887376bc6007c57cb35b905cc713e/output/feat_transform/preprocessing_model.tar.gz',\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    sagemaker_session=session,\n",
    "    source_dir='src/model_deploy',\n",
    "    entry_point='preprocessing_inference.py',\n",
    "    framework_version='0.23-1',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = preprocessing_model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.c5.xlarge', \n",
    "                         endpoint_name='tfm-v3-preprocessing-endpoint-test-v23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SOURCE': {'0': 'AMADEUS-MPIS'}, 'JOURNEY_TYPE': {'0': 'ROUNDTRIP'}, 'DEPARTURE_CLUSTER': {'0': 'ES'}, 'DESTINATION_CLUSTER': {'0': 'City'}, 'ttd_cluster': {'0': 'A'}, 'OUT_ELAPSED_FLIGHT_TIME': {'0': 140}, 'NUM_PAX': {'0': 3}, 'TOTAL_MARKUP_AMOUNT_PER_PAX': {'0': 15}, 'DAYSTODEP': {'0': 15}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features': ['JOURNEY_TYPE',\n",
       "  'DEPARTURE_CLUSTER',\n",
       "  'DESTINATION_CLUSTER',\n",
       "  'ttd_cluster',\n",
       "  'AF',\n",
       "  'AMADEUS-MPIS',\n",
       "  'AMADEUS-MPTB',\n",
       "  'EK',\n",
       "  'FLX',\n",
       "  'KL',\n",
       "  'XQ',\n",
       "  'LONG_HAUL',\n",
       "  'SHORT_HAUL',\n",
       "  'DAYSTODEP',\n",
       "  'NUM_PAX',\n",
       "  'TOTAL_MARKUP_AMOUNT_PER_PAX'],\n",
       " 'tfm_v3_data': [['ROUNDTRIP',\n",
       "   'ES',\n",
       "   'City',\n",
       "   'A',\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.04620462046204621,\n",
       "   2.0,\n",
       "   0.7692307692307692]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "content_type = \"application/json\"\n",
    "request_body = {\n",
    "    \"SOURCE\":{\"0\":\"AMADEUS-MPIS\"},\n",
    "    \"JOURNEY_TYPE\":{\"0\":\"ROUNDTRIP\"},\n",
    "    \"DEPARTURE_CLUSTER\":{\"0\":\"ES\"},\n",
    "    \"DESTINATION_CLUSTER\":{\"0\":\"City\"},\n",
    "    \"ttd_cluster\":{\"0\":\"A\"},\n",
    "    \"OUT_ELAPSED_FLIGHT_TIME\":{\"0\":140},\n",
    "    \"NUM_PAX\":{\"0\":3},\n",
    "    \"TOTAL_MARKUP_AMOUNT_PER_PAX\":{\"0\":15},\n",
    "    \"DAYSTODEP\":{\"0\":15},\n",
    "}\n",
    "endpoint_name = \"tfm-v3-preprocessing-endpoint-test-v23\"\n",
    "print(request_body)\n",
    "\n",
    "import json\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=content_type,\n",
    "    Body=payload)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local deployment\n",
    "This has to be done outside sagemaker studio!\n",
    "Before we can get started we have the usual SageMaker imports to get our environment ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/rl-market-simulator\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess\n",
    "\n",
    "#Setup\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Local Mode Serving\n",
    "First we create a SageMaker Local Session, this is essentially telling SageMaker we’re working in Local Mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sagemaker.local.local_session.LocalSession'>\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.local import LocalSession\n",
    "from sagemaker.sklearn import SKLearn, SKLearnModel\n",
    "\n",
    "session = LocalSession()\n",
    "print(type(session))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we configure our SKLearn SageMaker estimator with Local Mode enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.config = {'local': {'local_code': True}}\n",
    "\n",
    "model = SKLearnModel(\n",
    "    entry_point='src/model_deploy/preprocessing_inference.py',\n",
    "    role=role,\n",
    "    model_data='s3://sagemaker-eu-central-1-961105418118/Process-TFM-V3-data-66e680777166619f25191b8fcfb2ed7f/output/feat_transform/preprocessing_model.tar.gz',\n",
    "    framework_version='0.23-1',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'docker-compose' is not installed. Local Mode features will not work without docker-compose. For more information on how to install 'docker-compose', please, see https://docs.docker.com/compose/install/\n"
     ]
    }
   ],
   "source": [
    "json_payload = '{\"SOURCE\":{\"0\":\"AMADEUS-MPIS\"},\"JOURNEY_TYPE\":{\"0\":\"ROUNDTRIP\"},\"OUT_ELAPSED_FLIGHT_TIME\":{\"0\":140},\"TOTAL_PRICE\":{\"0\":220.57},\"DEPARTURE_CLUSTER\":{\"0\":\"ES\"},\"DESTINATION_CLUSTER\":{\"0\":\"City\"}}'\n",
    "\n",
    "try:\n",
    "    predictor = model.deploy(initial_instance_count=1, instance_type='local')\n",
    "    print(predictor)\n",
    "    preds = predictor.predict(payload)\n",
    "    print(preds)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "'docker-compose' is not installed. Local Mode features will not work without docker-compose. For more information on how to install 'docker-compose', please, see https://docs.docker.com/compose/install/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-27bdb5eed051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'local'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mdata_capture_config_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_request_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         self.sagemaker_session.endpoint_from_production_variants(\n\u001b[0m\u001b[1;32m    784\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mproduction_variants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3572\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   3069\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_append_project_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         self.sagemaker_client.create_endpoint(\n\u001b[0m\u001b[1;32m   3072\u001b[0m             \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, EndpointName, EndpointConfigName, Tags)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalEndpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         self.container = _SageMakerContainer(\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, instance_type, instance_count, image, sagemaker_session, container_entrypoint, container_arguments)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# check if docker-compose is installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfind_executable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"docker-compose\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0;34m\"'docker-compose' is not installed. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;34m\"Local Mode features will not work without docker-compose. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: 'docker-compose' is not installed. Local Mode features will not work without docker-compose. For more information on how to install 'docker-compose', please, see https://docs.docker.com/compose/install/"
     ]
    }
   ],
   "source": [
    "model.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
